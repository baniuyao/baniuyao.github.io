<!doctype html>
<html class="theme-next use-motion ">
<head>
  

<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />








  <link rel="stylesheet" type="text/css" href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5"/>



  <link href='//fonts.googleapis.com/css?family=Lato:300,400,700,400italic&subset=latin,latin-ext' rel='stylesheet' type='text/css'>


<link rel="stylesheet" type="text/css" href="/css/main.css?v=0.4.5.1"/>




  <meta name="keywords" content="Hexo,next" />



  <link rel="alternate" href="/atom.xml" title="Renjie Yao's Blog" type="application/atom+xml" />



  <link rel="shorticon icon" type="image/x-icon" href="/favicon.ico?v=0.4.5.1" />


<meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="Renjie Yao's Blog">
<meta property="og:url" content="http://blog.yaorenjie.com/index.html">
<meta property="og:site_name" content="Renjie Yao's Blog">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Renjie Yao's Blog">
<meta name="twitter:description">


<script type="text/javascript" id="hexo.configuration">
  var CONFIG = {
    scheme: '',
    sidebar: 'post'
  };
</script>

  <title> Renjie Yao's Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  <!--[if lte IE 8]>
  <div style=' clear: both; height: 59px; padding:0 0 0 15px; position: relative;margin:0 auto;'>
    <a href="http://windows.microsoft.com/en-US/internet-explorer/products/ie/home?ocid=ie6_countdown_bannercode">
      <img src="http://7u2nvr.com1.z0.glb.clouddn.com/picouterie.jpg" border="0" height="42" width="820"
           alt="You are using an outdated browser. For a faster, safer browsing experience, upgrade for free today or use other browser ,like chrome firefox safari."
           style='margin-left:auto;margin-right:auto;display: block;'/>
    </a>
  </div>
<![endif]-->
  

  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?14c861085b24e8d70ed28c14d40e7cbc";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>



  <div class="container one-column 
   page-home 
">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><h1 class="site-meta">
  <span class="logo-line-before"><i></i></span>
  <a href="/" class="brand" rel="start">
      <span class="logo">
        <i class="icon-next-logo"></i>
      </span>
      <span class="site-title">Renjie Yao's Blog</span>
  </a>
  <span class="logo-line-after"><i></i></span>
</h1>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu ">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            <i class="menu-item-icon icon-next-home"></i> <br />
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            <i class="menu-item-icon icon-next-archives"></i> <br />
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            <i class="menu-item-icon icon-next-tags"></i> <br />
            Tags
          </a>
        </li>
      

      
      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div id="content" class="content"> 
  <section id="posts" class="posts-expand">
    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/07/23/Install-Octave-on-Mac-Sierra/" itemprop="url">
                Install Octave on Mac Sierra
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          Posted on
          <time itemprop="dateCreated" datetime="2017-07-23T18:36:42+08:00" content="2017-07-23">
            2017-07-23
          </time>
        </span>

        

        
          
            <span class="post-comments-count">
            &nbsp; | &nbsp;
            <a href="/2017/07/23/Install-Octave-on-Mac-Sierra/#comments" itemprop="discussionUrl">
              <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/23/Install-Octave-on-Mac-Sierra/" itemprop="commentsCount"></span>
            </a>
          </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><h1 id="Learning_Machine_Learning">Learning Machine Learning</h1><p>I’ve joined ViSenze for almost half a year, and our CTO said we (me and Terry) should learn some machine learning knowledge, since there are a lot of Phd here in our company:). He recommended a course on Coursera - <a href="https://www.coursera.org/learn/neural-networks" target="_blank" rel="external">Neural Networks for Machine Learning</a>.</p>
<p>I am facing the Quiz of Week 3, while it needs some coding works in Octave. </p>
<h1 id="Problems">Problems</h1><p>The Macbook, which lays in my home, hasn’t been used for quite a time. When I use <code>brew</code> to install Octave, some weird issue happened:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Error: uninitialized constant Formulary::FormulaNamespacefe4ce29a01455f41d6d0b08c39f76615::Octave::DevelopmentTools</span><br><span class="line">Please report this bug:</span><br><span class="line">    https://git.io/brew-troubleshooting</span><br><span class="line">/usr/<span class="built_in">local</span>/Library/Taps/homebrew/homebrew-science/octave.rb:<span class="number">31</span>:<span class="keyword">in</span> `&lt;class:Octave&gt;<span class="string">'</span><br><span class="line">/usr/local/Library/Taps/homebrew/homebrew-science/octave.rb:1:in `load_formula'</span></span><br><span class="line">/usr/<span class="built_in">local</span>/Library/Homebrew/formulary.rb:<span class="number">21</span>:<span class="keyword">in</span> `module_<span class="built_in">eval</span><span class="string">'</span><br><span class="line">/usr/local/Library/Homebrew/formulary.rb:21:in `load_formula'</span></span><br><span class="line">/usr/<span class="built_in">local</span>/Library/Homebrew/formulary.rb:<span class="number">38</span>:<span class="keyword">in</span> `load_formula_from_path<span class="string">'</span><br><span class="line">/usr/local/Library/Homebrew/formulary.rb:87:in `load_file'</span></span><br><span class="line">/usr/<span class="built_in">local</span>/Library/Homebrew/formulary.rb:<span class="number">78</span>:<span class="keyword">in</span> `klass<span class="string">'</span><br><span class="line">/usr/local/Library/Homebrew/formulary.rb:74:in `get_formula'</span></span><br><span class="line">/usr/<span class="built_in">local</span>/Library/Homebrew/formulary.rb:<span class="number">171</span>:<span class="keyword">in</span> `get_formula<span class="string">'</span><br><span class="line">/usr/local/Library/Homebrew/formulary.rb:211:in `factory'</span></span><br><span class="line">/usr/<span class="built_in">local</span>/Library/Homebrew/extend/ARGV.rb:<span class="number">18</span>:<span class="keyword">in</span> `block <span class="keyword">in</span> formulae<span class="string">'</span><br><span class="line">/usr/local/Library/Homebrew/extend/ARGV.rb:16:in `map'</span></span><br><span class="line">/usr/<span class="built_in">local</span>/Library/Homebrew/extend/ARGV.rb:<span class="number">16</span>:<span class="keyword">in</span> `formulae<span class="string">'</span><br><span class="line">/usr/local/Library/Homebrew/cmd/install.rb:95:in `install'</span></span><br><span class="line">/usr/<span class="built_in">local</span>/Library/brew.rb:<span class="number">87</span>:<span class="keyword">in</span> `&lt;main&gt;<span class="string">'</span></span><br></pre></td></tr></table></figure>
<h1 id="Solution">Solution</h1><p>I found there is guide on Octave <a href="http://wiki.octave.org/Octave_for_MacOS_X#Simple_Installation_Instructions_2" target="_blank" rel="external">Wiki</a>. Let me summarize it:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo chown -R $(whoami) /usr/<span class="built_in">local</span></span><br><span class="line">brew update &amp;&amp; brew upgrade <span class="comment"># it will take some time</span></span><br><span class="line">brew cask install xquartz</span><br><span class="line">brew install octave <span class="comment"># it will take a lot of time...</span></span><br></pre></td></tr></table></figure>
<h1 id="After_brew_install_octave">After brew install octave</h1><p>When I typed ‘octave’ in my terminal, there is an issue like:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$octave</span></span><br><span class="line">dyld: Library not loaded: /usr/<span class="built_in">local</span>/opt/suite-sparse/lib/libsuitesparseconfig.<span class="number">4.5</span>.<span class="number">4</span>.dylib</span><br><span class="line">  Referenced from: /usr/<span class="built_in">local</span>/bin/octave</span><br><span class="line">  Reason: image not found</span><br><span class="line">Abort <span class="built_in">trap</span>: <span class="number">6</span></span><br></pre></td></tr></table></figure>
<p>And actually I’ve already installed <code>suite-sparse</code>, version 4.5.5. You need to create a soft link:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/opt/suite-sparse/lib/</span><br><span class="line">ln <span class="operator">-s</span> libsuitesparseconfig.<span class="number">4.5</span>.<span class="number">5</span>.dylib libsuitesparseconfig.<span class="number">4.5</span>.<span class="number">4</span>.dylib</span><br></pre></td></tr></table></figure>
<h1 id="Create_your_application">Create your application</h1><p>It is easier if we can launch octave in our Application, not in terminal. We can use <code>Script Editor</code> in macOS:</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tell application &#34;Terminal&#34;&#13;&#9;do script &#34;`which octave`; exit&#34;&#13;end tell</span><br></pre></td></tr></table></figure>
<h1 id="Screenshot">Screenshot</h1><p><img src="/images/octave.jpg" alt="Alt text"></p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/06/23/Maven-AWS-AccessDenied-Issue/" itemprop="url">
                Maven AWS AccessDenied Issue
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          Posted on
          <time itemprop="dateCreated" datetime="2017-06-23T11:53:35+08:00" content="2017-06-23">
            2017-06-23
          </time>
        </span>

        

        
          
            <span class="post-comments-count">
            &nbsp; | &nbsp;
            <a href="/2017/06/23/Maven-AWS-AccessDenied-Issue/#comments" itemprop="discussionUrl">
              <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/06/23/Maven-AWS-AccessDenied-Issue/" itemprop="commentsCount"></span>
            </a>
          </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>When I used mvn to package some java codes as usually, there happened a very weird exception:</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INFO] ------------------------------------------------------------------------&#10;[INFO] BUILD FAILURE&#10;[INFO] ------------------------------------------------------------------------&#10;[INFO] Total time: 28.410 s&#10;[INFO] Finished at: 2017-06-23T08:29:33+00:00&#10;[INFO] Final Memory: 50M/612M&#10;[INFO] ------------------------------------------------------------------------&#10;[ERROR] Failed to execute goal net.alchim31.maven:scala-maven-plugin:3.2.0:compile (scala-compile-first) on project analysis-spark: Execution scala-compile-first of goal net.alchim31.maven:scala-maven-plugin:3.2.0:compile failed: Status Code: 403, AWS Service: Amazon S3, AWS Request ID: 7967A1610B14A2BD, AWS Error Code: AccessDenied, AWS Error Message: Access Denied -&#62; [Help 1]&#10;[ERROR]&#10;[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.&#10;[ERROR] Re-run Maven using the -X switch to enable full debug logging.&#10;[ERROR]&#10;[ERROR] For more information about the errors and possible solutions, please read the following articles:&#10;[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/PluginExecutionException&#10;[ERROR]&#10;[ERROR] After correcting the problems, you can resume the build with the command&#10;[ERROR]   mvn &#60;goals&#62; -rf :analysis-spark</span><br></pre></td></tr></table></figure>
<p>The exception said that AWS access denied, as we use AWS in our maven settings like belowed:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">settings</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="title">servers</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">server</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="title">id</span>&gt;</span>maven-s3-release-repo<span class="tag">&lt;/<span class="title">id</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="title">username</span>&gt;</span>USERNAME<span class="tag">&lt;/<span class="title">username</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="title">password</span>&gt;</span>PASSWORD<span class="tag">&lt;/<span class="title">password</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="title">server</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">settings</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>And I have double checked the authentication information is correct while other developers can package successfully in their own computers.</p>
<p>Finally I found that the problem is because I set a environment variable in Mac:</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$env | grep AWS&#10;AWS_SECRET_ACCESS_KEY=XXXXX&#10;AWS_ACCESS_KEY_ID=XXXX</span><br></pre></td></tr></table></figure>
<p>After unset them, the package procedure became okay. I think that is because the ENV has higher priority than the configuration in <code>~/.m2/settings.xml</code>.</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/03/25/Join-ViSenze-in-Singapore/" itemprop="url">
                Join ViSenze in Singapore
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          Posted on
          <time itemprop="dateCreated" datetime="2017-03-25T22:20:02+08:00" content="2017-03-25">
            2017-03-25
          </time>
        </span>

        

        
          
            <span class="post-comments-count">
            &nbsp; | &nbsp;
            <a href="/2017/03/25/Join-ViSenze-in-Singapore/#comments" itemprop="discussionUrl">
              <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/03/25/Join-ViSenze-in-Singapore/" itemprop="commentsCount"></span>
            </a>
          </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><h1 id="Yes!_ViSenze">Yes! ViSenze</h1><p>It has been a long time since last post, I’m busy in settling down in Singapore these days. Yes, I joined ViSenze, a startup who has raised round B fund. I’ll act as a Data Platform Lead, to build our data product and technical architecture. ViSenze has so many excellent talents and I feel really happy with these guys in the last month. Hope we all have a great advantages.</p>
<h1 id="About_ViSenze">About ViSenze</h1><blockquote>
<p>ViSenze is an artificial intelligence company that develops advanced visual search and image recognition solutions to help businesses in eCommerce, mCommerce and online advertising.</p>
<p>Using R&amp;D in machine learning and computer vision technology, ViSenze can recommend visually similar items to online shoppers, either on e-commerce platforms when they browse or search by uploading a picture or on content publishers platforms like social media and video networks.</p>
<p>The company is a spin-off from NExT, a leading research centre jointly established between National University of Singapore and Tsinghua University of China.</p>
</blockquote>
<h1 id="Welcome">Welcome</h1><p><img src="/images/visenze_welcome.jpg" alt="Alt text"></p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/01/03/Kafka-0-10-Compression-Benchmark/" itemprop="url">
                Kafka 0.10 Compression Benchmark
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          Posted on
          <time itemprop="dateCreated" datetime="2017-01-03T17:09:51+08:00" content="2017-01-03">
            2017-01-03
          </time>
        </span>

        

        
          
            <span class="post-comments-count">
            &nbsp; | &nbsp;
            <a href="/2017/01/03/Kafka-0-10-Compression-Benchmark/#comments" itemprop="discussionUrl">
              <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/01/03/Kafka-0-10-Compression-Benchmark/" itemprop="commentsCount"></span>
            </a>
          </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><h1 id="Backgroud">Backgroud</h1><p>In my previous <a href="http://blog.yaorenjie.com/2015/03/27/Kafka-Compression-Performance-Tests/">blog about compression benchmark for Kafka</a>, I have made some tests for Kafka 0.8.2.1. Kafka 0.10 has made a lot of progress, and this post aims to make some benchmaks on Kafka 0.10. </p>
<p>In this post, I’m going to test 3 parts:</p>
<ol>
<li>Producer - time cost, throughput, bandwidth, total traffic</li>
<li>Consumer - time cost, throughput</li>
<li>Capacity - disk usage, server/client CPU usage</li>
</ol>
<h1 id="Environment">Environment</h1><h2 id="Hardware_Box">Hardware Box</h2><p>I use Docker on Mac to run two containers - zk and kafka.</p>
<table>
<thead>
<tr>
<th style="text-align:right">Mac CPUs</th>
<th style="text-align:right">Mac Memory</th>
<th style="text-align:right">Mac Disk</th>
<th style="text-align:right">Docker CPUs</th>
<th style="text-align:right">Docker Memory</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">2.5 GHz Intel Core i7</td>
<td style="text-align:right">16GB</td>
<td style="text-align:right">512GB SSD</td>
<td style="text-align:right">4</td>
<td style="text-align:right">2G</td>
</tr>
</tbody>
</table>
<p><code>docker-compose.yml</code> is below:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">version: <span class="string">"2"</span></span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  zk:</span><br><span class="line">    image: kafka-<span class="number">0.10</span>_zk:<span class="number">1</span></span><br><span class="line">    ports:</span><br><span class="line">      - <span class="string">"2181:2181"</span></span><br><span class="line"></span><br><span class="line">  kafka:</span><br><span class="line">    depends_on:</span><br><span class="line">      - zk</span><br><span class="line">    image: kafka-<span class="number">0.10</span>_kafka:<span class="number">1</span></span><br><span class="line">    ports:</span><br><span class="line">      - <span class="string">"9092:9092"</span></span><br><span class="line">      - <span class="string">"9999:9999"</span></span><br><span class="line">    command: --override zookeeper.connect=zk:<span class="number">2181</span></span><br></pre></td></tr></table></figure>
<h2 id="Software_Box">Software Box</h2><p><strong>All Kafka JVM parameters are default</strong> because the benchmark’s main purpose is to compare different compression algorithm to the <code>none</code> compression.</p>
<table>
<thead>
<tr>
<th style="text-align:right">Kafka Version</th>
<th style="text-align:right">JDK</th>
<th style="text-align:right">Scala</th>
<th style="text-align:right">Broker</th>
<th style="text-align:right">Kafka Replica</th>
<th style="text-align:right">Kafka Partition</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">0.10.1.0</td>
<td style="text-align:right">1.7.0-b147</td>
<td style="text-align:right">2.11</td>
<td style="text-align:right">1</td>
<td style="text-align:right">1</td>
<td style="text-align:right">1</td>
</tr>
</tbody>
</table>
<h2 id="Log_Files">Log Files</h2><p>The log file comes from nginx access logs, and it use 1.2GB disk space and it has 5,190,426 lines.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@<span class="number">780</span>e74bff80d kafka_2.<span class="number">11</span>-<span class="number">0.10</span>.<span class="number">1.0</span>]<span class="comment"># du -sh nginx.log</span></span><br><span class="line"><span class="number">1.2</span>G	nginx.log</span><br><span class="line">[root@<span class="number">780</span>e74bff80d kafka_2.<span class="number">11</span>-<span class="number">0.10</span>.<span class="number">1.0</span>]<span class="comment"># wc -l nginx.log</span></span><br><span class="line"><span class="number">5190426</span> nginx.log</span><br><span class="line">[root@<span class="number">780</span>e74bff80d kafka_2.<span class="number">11</span>-<span class="number">0.10</span>.<span class="number">1.0</span>]<span class="comment"># tail -1 nginx.log</span></span><br><span class="line"><span class="number">127.0</span>.<span class="number">0.1</span>	hello.com	<span class="number">127.0</span>.<span class="number">0.1</span>	<span class="number">127.0</span>.<span class="number">0.1</span>	- <span class="number">30</span>/Dec/<span class="number">2016</span>:<span class="number">09</span>:<span class="number">43</span>:<span class="number">28</span> +<span class="number">0800</span> POST /index.php HTTP/<span class="number">1.1</span> <span class="number">200</span> <span class="number">64</span> -Mozilla/<span class="number">4.0</span> (compatible; MSIE <span class="number">7.0</span>; Windows NT <span class="number">5.1</span>; Trident/<span class="number">4.0</span>; .NET CLR <span class="number">2.0</span>.<span class="number">50727</span>) <span class="number">127.0</span>.<span class="number">0.1</span>	<span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">80</span>	<span class="number">0.016</span>	<span class="number">0.016</span></span><br></pre></td></tr></table></figure>
<h1 id="Producer_Benchmark">Producer Benchmark</h1><p>To test Producer performance, I will use <code>kafka-console-producer.sh</code> to send <code>nginx.log</code> to kafka, <code>dstat</code> to get network metrics and <code>time</code> in linux to get the time costs. The details are below:</p>
<ol>
<li>time(second) - by Linux command <code>time</code></li>
<li>throughtput(message/second) - <code>total lines</code>/<code>time</code></li>
<li>bandwidth(MB/s) - by <code>dstat -nT</code></li>
<li>traffic(MB) - <code>bandwidth</code> * <code>time</code></li>
</ol>
<p>The command to send messsages is:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@a7dd0e808964 kafka_2.<span class="number">11</span>-<span class="number">0.10</span>.<span class="number">1.0</span>]<span class="comment"># time bin/kafka-console-producer.sh --broker-list a7dd0e808964:9092 --topic test_producer --batch-size 2000 --compression-codec none &lt; nginx.log</span></span><br></pre></td></tr></table></figure>
<p>The command to get network metrics is:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@a7dd0e808964 kafka_2.<span class="number">11</span>-<span class="number">0.10</span>.<span class="number">1.0</span>]<span class="comment"># dstat -nT</span></span><br><span class="line">-net/total- --epoch---</span><br><span class="line"> recv  send|  epoch</span><br><span class="line">   <span class="number">0</span>     <span class="number">0</span> |<span class="number">1483439091</span></span><br><span class="line">  <span class="number">86</span>B  <span class="number">144</span>B|<span class="number">1483439092</span></span><br><span class="line">   <span class="number">0</span>     <span class="number">0</span> |<span class="number">1483439093</span></span><br></pre></td></tr></table></figure>
<h2 id="Detail_Metrics_for_Every_Compression_Codecs">Detail Metrics for Every Compression Codecs</h2><h3 id="Compression_Codec:_none">Compression Codec: none</h3><table>
<thead>
<tr>
<th style="text-align:right">batch.size</th>
<th style="text-align:right">time(sec)</th>
<th style="text-align:right">throughput(msg/s)</th>
<th style="text-align:right">bandwidth (MB/s)</th>
<th style="text-align:right">traffic (MB)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right"><strong>500</strong></td>
<td style="text-align:right">35.067</td>
<td style="text-align:right">148014.54</td>
<td style="text-align:right">38.3</td>
<td style="text-align:right">1343.07</td>
</tr>
<tr>
<td style="text-align:right"><strong>1000</strong></td>
<td style="text-align:right">35.579</td>
<td style="text-align:right">145884.54</td>
<td style="text-align:right">37.2</td>
<td style="text-align:right">1323.54</td>
</tr>
<tr>
<td style="text-align:right"><strong>1500</strong></td>
<td style="text-align:right">35.656</td>
<td style="text-align:right">145569.5</td>
<td style="text-align:right">38.3</td>
<td style="text-align:right">1365.62</td>
</tr>
<tr>
<td style="text-align:right"><strong>5000</strong></td>
<td style="text-align:right">31.905</td>
<td style="text-align:right">162683.78</td>
<td style="text-align:right">41.8</td>
<td style="text-align:right">1333.63</td>
</tr>
<tr>
<td style="text-align:right"><strong>10000</strong></td>
<td style="text-align:right">35.212</td>
<td style="text-align:right">147405.03</td>
<td style="text-align:right">38.3</td>
<td style="text-align:right">1348.62</td>
</tr>
<tr>
<td style="text-align:right"><strong>AVERAGE</strong></td>
<td style="text-align:right">34.68</td>
<td style="text-align:right">149911.48</td>
<td style="text-align:right">38.78</td>
<td style="text-align:right">1342.9</td>
</tr>
</tbody>
</table>
<h3 id="Compression_Codec:_gzip">Compression Codec: gzip</h3><table>
<thead>
<tr>
<th style="text-align:right">batch.size</th>
<th style="text-align:right">time(sec)</th>
<th style="text-align:right">throughput(msg/s)</th>
<th style="text-align:right">bandwidth (MB/s)</th>
<th style="text-align:right">traffic (MB)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right"><strong>500</strong></td>
<td style="text-align:right">73.302</td>
<td style="text-align:right">70808.79</td>
<td style="text-align:right">2.0</td>
<td style="text-align:right">146.6</td>
</tr>
<tr>
<td style="text-align:right"><strong>1000</strong></td>
<td style="text-align:right">68.695</td>
<td style="text-align:right">75557.55</td>
<td style="text-align:right">2.0</td>
<td style="text-align:right">137.39</td>
</tr>
<tr>
<td style="text-align:right"><strong>1500</strong></td>
<td style="text-align:right">72.471</td>
<td style="text-align:right">71620.73</td>
<td style="text-align:right">2.0</td>
<td style="text-align:right">144.94</td>
</tr>
<tr>
<td style="text-align:right"><strong>5000</strong></td>
<td style="text-align:right">76.469</td>
<td style="text-align:right">67876.21</td>
<td style="text-align:right">2.0</td>
<td style="text-align:right">152.94</td>
</tr>
<tr>
<td style="text-align:right"><strong>10000</strong></td>
<td style="text-align:right">73.865</td>
<td style="text-align:right">70269.09</td>
<td style="text-align:right">2.0</td>
<td style="text-align:right">147.73</td>
</tr>
<tr>
<td style="text-align:right"><strong>AVERAGE</strong></td>
<td style="text-align:right">72.96</td>
<td style="text-align:right">71226.47</td>
<td style="text-align:right">2.0</td>
<td style="text-align:right">145.92</td>
</tr>
</tbody>
</table>
<h3 id="Compression_Codec:_snappy">Compression Codec: snappy</h3><table>
<thead>
<tr>
<th style="text-align:right">batch.size</th>
<th style="text-align:right">time(sec)</th>
<th style="text-align:right">throughput(msg/s)</th>
<th style="text-align:right">bandwidth (MB/s)</th>
<th style="text-align:right">traffic (MB)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right"><strong>500</strong></td>
<td style="text-align:right">29.163</td>
<td style="text-align:right">177979.84</td>
<td style="text-align:right">24.5</td>
<td style="text-align:right">714.49</td>
</tr>
<tr>
<td style="text-align:right"><strong>1000</strong></td>
<td style="text-align:right">33.959</td>
<td style="text-align:right">152843.9</td>
<td style="text-align:right">21.4</td>
<td style="text-align:right">726.72</td>
</tr>
<tr>
<td style="text-align:right"><strong>1500</strong></td>
<td style="text-align:right">31.152</td>
<td style="text-align:right">166616.14</td>
<td style="text-align:right">23.5</td>
<td style="text-align:right">732.07</td>
</tr>
<tr>
<td style="text-align:right"><strong>5000</strong></td>
<td style="text-align:right">27.420</td>
<td style="text-align:right">189293.440</td>
<td style="text-align:right">28.0</td>
<td style="text-align:right">767.76</td>
</tr>
<tr>
<td style="text-align:right"><strong>10000</strong></td>
<td style="text-align:right">28.019</td>
<td style="text-align:right">185246.65</td>
<td style="text-align:right">26.9</td>
<td style="text-align:right">753.71</td>
</tr>
<tr>
<td style="text-align:right"><strong>AVERAGE</strong></td>
<td style="text-align:right">29.94</td>
<td style="text-align:right">174395.99</td>
<td style="text-align:right">24.86</td>
<td style="text-align:right">738.95</td>
</tr>
</tbody>
</table>
<h3 id="Compression_Codec:_lz4">Compression Codec: lz4</h3><table>
<thead>
<tr>
<th style="text-align:right">batch.size</th>
<th style="text-align:right">time(sec)</th>
<th style="text-align:right">throughput(msg/s)</th>
<th style="text-align:right">bandwidth (MB/s)</th>
<th style="text-align:right">traffic (MB)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right"><strong>500</strong></td>
<td style="text-align:right">17.937</td>
<td style="text-align:right">289369.79</td>
<td style="text-align:right">14.01</td>
<td style="text-align:right">251.3</td>
</tr>
<tr>
<td style="text-align:right"><strong>1000</strong></td>
<td style="text-align:right">17.837</td>
<td style="text-align:right">290992.1</td>
<td style="text-align:right">13.70</td>
<td style="text-align:right">244.37</td>
</tr>
<tr>
<td style="text-align:right"><strong>1500</strong></td>
<td style="text-align:right">17.143</td>
<td style="text-align:right">302772.33</td>
<td style="text-align:right">14.03</td>
<td style="text-align:right">240.52</td>
</tr>
<tr>
<td style="text-align:right"><strong>5000</strong></td>
<td style="text-align:right">18.525</td>
<td style="text-align:right">280184.94</td>
<td style="text-align:right">13.43</td>
<td style="text-align:right">248.79</td>
</tr>
<tr>
<td style="text-align:right"><strong>10000</strong></td>
<td style="text-align:right">20.567</td>
<td style="text-align:right">252366.7</td>
<td style="text-align:right">11.76</td>
<td style="text-align:right">241.87</td>
</tr>
<tr>
<td style="text-align:right"><strong>AVERAGE</strong></td>
<td style="text-align:right">18.4</td>
<td style="text-align:right">283137.17</td>
<td style="text-align:right">13.39</td>
<td style="text-align:right">245.37</td>
</tr>
</tbody>
</table>
<h2 id="Summary">Summary</h2><table>
<thead>
<tr>
<th style="text-align:right">codec</th>
<th style="text-align:right">throughput</th>
<th style="text-align:right">bandwidth</th>
<th style="text-align:right">traffic</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right"><strong>none</strong></td>
<td style="text-align:right">149911.48</td>
<td style="text-align:right">38.78</td>
<td style="text-align:right">1342.9</td>
</tr>
<tr>
<td style="text-align:right"><strong>gzip</strong></td>
<td style="text-align:right">71226.47</td>
<td style="text-align:right">2.0</td>
<td style="text-align:right">145.92</td>
</tr>
<tr>
<td style="text-align:right"><strong>snappy</strong></td>
<td style="text-align:right">174395.99</td>
<td style="text-align:right">24.86</td>
<td style="text-align:right">738.95</td>
</tr>
<tr>
<td style="text-align:right"><strong>lz4</strong></td>
<td style="text-align:right">283137.17</td>
<td style="text-align:right">13.39</td>
<td style="text-align:right">245.37</td>
</tr>
</tbody>
</table>
<h3 id="Throughput_Overview">Throughput Overview</h3><p><img src="/images/kafka010/producer_throughput.png" alt="Alt text"></p>
<h3 id="Bandwidth_Overview">Bandwidth Overview</h3><p><img src="/images/kafka010/producer_bandwidth.png" alt="Alt text"></p>
<h3 id="Traffic_Overview">Traffic Overview</h3><p><img src="/images/kafka010/producer_traffic.png" alt="Alt text"></p>
<h3 id="Percentage_Overview">Percentage Overview</h3><table>
<thead>
<tr>
<th style="text-align:right">codec</th>
<th style="text-align:right">throughput%</th>
<th style="text-align:right">bandwidth%</th>
<th style="text-align:right">traffic%</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right"><strong>gzip</strong></td>
<td style="text-align:right">47.51</td>
<td style="text-align:right">5.16</td>
<td style="text-align:right">10.87</td>
</tr>
<tr>
<td style="text-align:right"><strong>snappy</strong></td>
<td style="text-align:right">116.33</td>
<td style="text-align:right">64.11</td>
<td style="text-align:right">55.03</td>
</tr>
<tr>
<td style="text-align:right"><strong>lz4</strong></td>
<td style="text-align:right">188.87</td>
<td style="text-align:right">34.53</td>
<td style="text-align:right">18.27</td>
</tr>
</tbody>
</table>
<p><img src="/images/kafka010/producer_overview.png" alt="Alt text"></p>
<h1 id="Consumer_Benchmark">Consumer Benchmark</h1><p>Tests for <code>Consumer</code> is much more easier than the one for <code>Producer</code>. Before tests, I will send the same <code>nginx.log</code> to Kafka with different compression codec - <code>none</code>, <code>gzip</code>, <code>snappy</code> and <code>lz4</code>. And use <code>kafka-console-consumer.sh</code> to consume a fixed number of messages and in this tests the number is 500k(5,000,000). What I need to look for is the time the procedure costs, and furthermore, we can get the throughput.</p>
<p>The bash command is:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">time bin/kafka-console-consumer.sh --bootstrap-server <span class="number">97200</span>db31e2c:<span class="number">9092</span> --topic consumer_none --max-messages <span class="number">5000000</span> --from-beginning &gt; /dev/null</span><br></pre></td></tr></table></figure>
<h2 id="Detail_Metrics">Detail Metrics</h2><table>
<thead>
<tr>
<th style="text-align:right">codec</th>
<th style="text-align:right">time(second)</th>
<th style="text-align:right">throughput(msg/s)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right"><strong>none</strong></td>
<td style="text-align:right">19.046</td>
<td style="text-align:right">262522.31</td>
</tr>
<tr>
<td style="text-align:right"><strong>gzip</strong></td>
<td style="text-align:right">39.493</td>
<td style="text-align:right">126604.71</td>
</tr>
<tr>
<td style="text-align:right"><strong>snappy</strong></td>
<td style="text-align:right">25.632</td>
<td style="text-align:right">195068.66</td>
</tr>
<tr>
<td style="text-align:right"><strong>lz4</strong></td>
<td style="text-align:right">23.846</td>
<td style="text-align:right">209678.77</td>
</tr>
</tbody>
</table>
<p><img src="/images/kafka010/consumer_overview.png" alt="Alt text"></p>
<p>Percentage:</p>
<table>
<thead>
<tr>
<th style="text-align:right">codec</th>
<th style="text-align:right">time%</th>
<th style="text-align:right">throughput%</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right"><strong>gzip</strong></td>
<td style="text-align:right">207.36</td>
<td style="text-align:right">48.23</td>
</tr>
<tr>
<td style="text-align:right"><strong>snappy</strong></td>
<td style="text-align:right">134.58</td>
<td style="text-align:right">74.31</td>
</tr>
<tr>
<td style="text-align:right"><strong>lz4</strong></td>
<td style="text-align:right">125.2</td>
<td style="text-align:right">79.87</td>
</tr>
</tbody>
</table>
<p><img src="/images/kafka010/consumer_overview_percentage.png" alt="Alt text"></p>
<h1 id="Capacity_Benchmark">Capacity Benchmark</h1><p>In the previous blog, I have not make tests for this section. The pressure each codec cause to the CPU is another important factor to consider. I will make some simple benchmark in disk space and CPU in this section by <code>dstat</code>.</p>
<h2 id="Disk_Usage">Disk Usage</h2><p>Although Kafka has its own retention policies, and it works well, but sometimes the disk space could be in engineers’ consideration, especially in large Kafka cluster. In the former section, I have sent <code>nginx.log</code> to Kafka with different codecs and I measured the the disk space each topic has used. The numbers can simply be got by <code>du -sh</code> in Kafka logs directory.</p>
<table>
<thead>
<tr>
<th style="text-align:right">codec</th>
<th style="text-align:right">Disk Space(MB)</th>
<th style="text-align:right">Percentage%</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right"><strong>none</strong></td>
<td style="text-align:right">1329.53</td>
<td style="text-align:right">100</td>
</tr>
<tr>
<td style="text-align:right"><strong>gzip</strong></td>
<td style="text-align:right">140.18</td>
<td style="text-align:right">10.54</td>
</tr>
<tr>
<td style="text-align:right"><strong>snappy</strong></td>
<td style="text-align:right">679.81</td>
<td style="text-align:right">51.13</td>
</tr>
<tr>
<td style="text-align:right"><strong>lz4</strong></td>
<td style="text-align:right">222.58</td>
<td style="text-align:right">16.74</td>
</tr>
</tbody>
</table>
<p><img src="/images/kafka010/capacity_disk_space.png" alt="Alt text"></p>
<h2 id="CPU_Usage">CPU Usage</h2><p>Compression and de-compression will mainly use cpu and I will record the <code>usr</code>, <code>sys</code>, <code>wait</code> and the total of them to measure how much CPU each codec will use. The data is made by <code>dstat</code> as well. Pay attention that my docker only has 4 CPU and this tests are mainly used to compare with different codec, not to dig into the absoulute number because it would be different in different boxes.</p>
<p>The test is simple, I used <code>dstat</code> to record the system metrics I want, and meanwhile, use <code>kafka-console-producer.sh</code> or <code>kafka-console-consumers.sh</code> in another container (not the Kafka container) to send or consume data from Kafka. </p>
<p>I will record metrics of both client(run console shell) and server(run Kafka server).</p>
<h3 id="Producer_CPU_Usage">Producer CPU Usage</h3><h4 id="Server_Side">Server Side</h4><p>Metrics</p>
<table>
<thead>
<tr>
<th style="text-align:right">codec</th>
<th style="text-align:right">usr</th>
<th style="text-align:right">sys</th>
<th style="text-align:right">wait</th>
<th style="text-align:right">total</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right"><strong>none</strong></td>
<td style="text-align:right">41.08</td>
<td style="text-align:right">6.56</td>
<td style="text-align:right">7.08</td>
<td style="text-align:right">54.72</td>
</tr>
<tr>
<td style="text-align:right"><strong>gzip</strong></td>
<td style="text-align:right">31.28</td>
<td style="text-align:right">1.70</td>
<td style="text-align:right">0.45</td>
<td style="text-align:right">33.43</td>
</tr>
<tr>
<td style="text-align:right"><strong>snappy</strong></td>
<td style="text-align:right">36.89</td>
<td style="text-align:right">4.12</td>
<td style="text-align:right">4.13</td>
<td style="text-align:right">45.14</td>
</tr>
<tr>
<td style="text-align:right"><strong>lz4</strong></td>
<td style="text-align:right">33.72</td>
<td style="text-align:right">2.77</td>
<td style="text-align:right">1.37</td>
<td style="text-align:right">37.86</td>
</tr>
</tbody>
</table>
<p>Chart</p>
<p><img src="/images/kafka010/capacity_producer_server_cpu.png" alt="Alt text"></p>
<h4 id="Client_side">Client side</h4><p>Metrics</p>
<table>
<thead>
<tr>
<th style="text-align:right">codec</th>
<th style="text-align:right">usr</th>
<th style="text-align:right">sys</th>
<th style="text-align:right">wait</th>
<th style="text-align:right">total</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right"><strong>none</strong></td>
<td style="text-align:right">41.00</td>
<td style="text-align:right">6.52</td>
<td style="text-align:right">7.09</td>
<td style="text-align:right">54.61</td>
</tr>
<tr>
<td style="text-align:right"><strong>gzip</strong></td>
<td style="text-align:right">31.28</td>
<td style="text-align:right">1.70</td>
<td style="text-align:right">0.44</td>
<td style="text-align:right">33.42</td>
</tr>
<tr>
<td style="text-align:right"><strong>snappy</strong></td>
<td style="text-align:right">36.65</td>
<td style="text-align:right">4.13</td>
<td style="text-align:right">4.07</td>
<td style="text-align:right">44.85</td>
</tr>
<tr>
<td style="text-align:right"><strong>lz4</strong></td>
<td style="text-align:right">33.70</td>
<td style="text-align:right">2.76</td>
<td style="text-align:right">1.36</td>
<td style="text-align:right">37.82</td>
</tr>
</tbody>
</table>
<p>Chart</p>
<p><img src="/images/kafka010/capacity_producer_client_cpu.png" alt="Alt text"></p>
<h3 id="Consumer_CPU_Usage">Consumer CPU Usage</h3><h4 id="Server_side">Server side</h4><p>Metrics</p>
<table>
<thead>
<tr>
<th style="text-align:right">codec</th>
<th style="text-align:right">usr</th>
<th style="text-align:right">sys</th>
<th style="text-align:right">wait</th>
<th style="text-align:right">total</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right"><strong>none</strong></td>
<td style="text-align:right">19.41</td>
<td style="text-align:right">5.05</td>
<td style="text-align:right">7.74</td>
<td style="text-align:right">32.2</td>
</tr>
<tr>
<td style="text-align:right"><strong>gzip</strong></td>
<td style="text-align:right">25.63</td>
<td style="text-align:right">1.43</td>
<td style="text-align:right">0.47</td>
<td style="text-align:right">27.53</td>
</tr>
<tr>
<td style="text-align:right"><strong>snappy</strong></td>
<td style="text-align:right">23.92</td>
<td style="text-align:right">4.23</td>
<td style="text-align:right">3.90</td>
<td style="text-align:right">32.05</td>
</tr>
<tr>
<td style="text-align:right"><strong>lz4</strong></td>
<td style="text-align:right">24.13</td>
<td style="text-align:right">2.35</td>
<td style="text-align:right">0.90</td>
<td style="text-align:right">27.38</td>
</tr>
</tbody>
</table>
<p>Chart</p>
<p><img src="/images/kafka010/capacity_consumer_server_cpu.png" alt="Alt text"></p>
<h4 id="Client_Side">Client Side</h4><p>Metrics</p>
<table>
<thead>
<tr>
<th style="text-align:right">codec</th>
<th style="text-align:right">usr</th>
<th style="text-align:right">sys</th>
<th style="text-align:right">wait</th>
<th style="text-align:right">total</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right"><strong>none</strong></td>
<td style="text-align:right">19.47</td>
<td style="text-align:right">5.05</td>
<td style="text-align:right">7.77</td>
<td style="text-align:right">32.29</td>
</tr>
<tr>
<td style="text-align:right"><strong>gzip</strong></td>
<td style="text-align:right">18.84</td>
<td style="text-align:right">1.16</td>
<td style="text-align:right">0.41</td>
<td style="text-align:right">20.41</td>
</tr>
<tr>
<td style="text-align:right"><strong>snappy</strong></td>
<td style="text-align:right">23.82</td>
<td style="text-align:right">4.36</td>
<td style="text-align:right">3.86</td>
<td style="text-align:right">32.04</td>
</tr>
<tr>
<td style="text-align:right"><strong>lz4</strong></td>
<td style="text-align:right">24.13</td>
<td style="text-align:right">2.35</td>
<td style="text-align:right">0.91</td>
<td style="text-align:right">27.39</td>
</tr>
</tbody>
</table>
<p>Chart</p>
<p><img src="/images/kafka010/capacity_consumer_client_cpu.png" alt="Alt text"></p>
<h1 id="Conclusion">Conclusion</h1><p><code>GZIP</code> has the best compression rate but lowest performance, and <code>LZ4</code> has the best performance. In the aspect of capacity, <code>GZIP</code> and <code>NONE</code> will cause wome <code>wait</code> which I don’t know the reason for that. Actually, the CPU usage for each codec is almost the same, I think capacity won’t be the main cause to choose different codecs.</p>
<p>To summarize the benchmarks briefly, use <code>GZIP</code> if you need cost less bandwidth and disk space, use <code>LZ4</code> to maximum the performance</p>
<p>There is also one problem this benchmark has not cover - how much CPU usage would Kafka server use when there are a huge number of clients. Will the increase of the server-side CPU usage be the linear growth with the number of client? I have not made this test because I only have two containers.</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2016/12/01/The-Comparsion-Between-Apache-Flume-and-Heka/" itemprop="url">
                The Comparsion Between Apache Flume and Heka
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          Posted on
          <time itemprop="dateCreated" datetime="2016-12-01T17:45:32+08:00" content="2016-12-01">
            2016-12-01
          </time>
        </span>

        

        
          
            <span class="post-comments-count">
            &nbsp; | &nbsp;
            <a href="/2016/12/01/The-Comparsion-Between-Apache-Flume-and-Heka/#comments" itemprop="discussionUrl">
              <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/12/01/The-Comparsion-Between-Apache-Flume-and-Heka/" itemprop="commentsCount"></span>
            </a>
          </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><h1 id="Environment">Environment</h1><p>This test’s main purpose is to choose the tool used to collect log on servers. In this test, we use Apache Flume and Heka to collect raw log data and send them into Kafka. The Kafka is in all default configuration. Linux is CentOS 6.4 with 12 cores CPU, 45GB memory and JDK 1.7.</p>
<h2 id="Benchmark_Metrics">Benchmark Metrics</h2><ol>
<li>mps - Message Per Second: This data is fetched from JMX port of Kafka. We get the total message count from Kafka, and then get this count again. The delta value is the message count in 1 second - mps. We can get mps by command line:</li>
</ol>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -jar /tmp/cmdline-jmxclient-0.10.3.jar - localhost:9999 kafk&#13;a.server:name=MessagesInPerSec,type=BrokerTopicMetrics Count</span><br></pre></td></tr></table></figure>
<ol>
<li>channelSize (only for Flume): This metrics is the number of messages Flume cannot handle in a while. It can be a measurement to determin if the Flume is health. A health Flume instance should keep this value in a low number. We can get this value by Flume http service:</li>
</ol>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -s localhost:34545/metrics | python -m json.tool | grep Channe&#13;lSize</span><br></pre></td></tr></table></figure>
<ol>
<li>%cpu and %mem: We get these two values directly by linux <code>top</code> command:</li>
</ol>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flume_pid=`jps -m | grep App | cut -d&#39; &#39; -f1`&#13;flume_cpu=`top -b -n1 -p $flume_pid | grep $flume_pid | awk &#39;&#123;print&#13;$9&#125;&#39;`&#13;flume_mem=`top -b -n1 -p $flume_pid | grep $flume_pid | awk &#39;&#123;print&#13;$10&#125;&#39;`</span><br></pre></td></tr></table></figure>
<h2 id="Benchmark_Items">Benchmark Items</h2><p>We used a tool to write log lines into log files with different mps - 5K, 10K, 50K.</p>
<h1 id="Flume_Benchmarks">Flume Benchmarks</h1><h2 id="Flume_Configuration">Flume Configuration</h2><p><strong>JVM</strong></p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPTS=&#34;-Xms256m -Xmx256m -Dflume.monitoring.type=http -Dflume.monitoring.port=34545&#34;</span><br></pre></td></tr></table></figure>
<p><strong>Flume Configuration</strong></p>
<pre><code>agent<span class="class">.sources</span> = fileSource
agent<span class="class">.channels</span> = diskChannel memChannel
agent<span class="class">.sinks</span> = kafkaSink

agent<span class="class">.sources</span><span class="class">.fileSource</span><span class="class">.type</span> = exec
agent<span class="class">.sources</span><span class="class">.fileSource</span><span class="class">.command</span> = tail -F /tmp/example<span class="class">.log</span>
agent<span class="class">.sources</span><span class="class">.fileSource</span><span class="class">.channels</span> = memChannel

agent<span class="class">.channels</span><span class="class">.memChannel</span><span class="class">.type</span> = memory
agent<span class="class">.channels</span><span class="class">.memChannel</span><span class="class">.capacity</span> = <span class="number">1000000</span>
agent<span class="class">.channels</span><span class="class">.memChannel</span><span class="class">.transactionCapacity</span> = <span class="number">10000</span>

agent<span class="class">.sinks</span><span class="class">.kafkaSink</span><span class="class">.type</span> = org<span class="class">.apache</span><span class="class">.flume</span><span class="class">.sink</span><span class="class">.kafka</span><span class="class">.KafkaSink</span>
agent<span class="class">.sinks</span><span class="class">.kafkaSink</span><span class="class">.topic</span> = flume_test
agent<span class="class">.sinks</span><span class="class">.kafkaSink</span><span class="class">.brokerList</span> = kafka:<span class="number">9092</span>
agent<span class="class">.sinks</span><span class="class">.kafkaSink</span><span class="class">.batchSize</span> = <span class="number">200</span>
agent<span class="class">.sinks</span><span class="class">.kafkaSink</span><span class="class">.channel</span> = memChannel
</code></pre><h2 id="Flume_Benchmark_Results">Flume Benchmark Results</h2><h3 id="5K_mps">5K mps</h3><p><img src="/images/flume_heka/flume_5k_mps.png" alt="Alt text"></p>
<p><img src="/images/flume_heka/flume_5k_mem.png" alt="Alt text"></p>
<h3 id="10K_mps">10K mps</h3><p><img src="/images/flume_heka/flume_10k_mps.png" alt="Alt text"></p>
<p><img src="/images/flume_heka/flume_10k_mem.png" alt="Alt text"></p>
<h3 id="50K_mps">50K mps</h3><p><img src="/images/flume_heka/flume_50k_mps.png" alt="Alt text"></p>
<p><img src="/images/flume_heka/flume_50k_mem.png" alt="Alt text"></p>
<h1 id="Heka_Benchmarks">Heka Benchmarks</h1><h2 id="Heka_Configuration">Heka Configuration</h2><pre><code><span class="title">[accesslogs]</span>
<span class="setting">type = <span class="value"><span class="string">"LogstreamerInput"</span></span></span>
<span class="setting">log_directory = <span class="value"><span class="string">"/tmp"</span></span></span>
<span class="setting">file_match = <span class="value"><span class="string">'example\.log'</span></span></span>
<span class="title">
[PayloadEncoder]</span>
<span class="setting">append_newlines = <span class="value"><span class="keyword">false</span></span></span>
<span class="title">
[KafkaOutput]</span>
<span class="setting">type = <span class="value"><span class="string">"KafkaOutput"</span></span></span>
<span class="setting">message_matcher = <span class="value"><span class="string">"TRUE"</span></span></span>
<span class="setting">topic = <span class="value"><span class="string">"heka_test"</span></span></span>
<span class="setting">addrs = <span class="value">[<span class="string">"kafka:9092"</span>]</span></span>
<span class="setting">encoder = <span class="value"><span class="string">"PayloadEncoder"</span></span></span>
<span class="setting">max_buffer_time = <span class="value"><span class="number">1000</span></span></span>
<span class="setting">max_buffered_bytes = <span class="value"><span class="number">1048576</span></span></span>
<span class="setting">required_acks = <span class="value"><span class="string">"NoResponse"</span></span></span>
</code></pre><h2 id="Heka_Benchmark_Results">Heka Benchmark Results</h2><h3 id="5K_mps-1">5K mps</h3><p><img src="/images/flume_heka/heka_5k_mps.png" alt="Alt text"></p>
<p><img src="/images/flume_heka/heka_5k_mem.png" alt="Alt text"></p>
<h3 id="10K_mps-1">10K mps</h3><p><img src="/images/flume_heka/heka_10k_mps.png" alt="Alt text"></p>
<p><img src="/images/flume_heka/heka_10k_mem.png" alt="Alt text"></p>
<h3 id="50K_mps-1">50K mps</h3><p><img src="/images/flume_heka/heka_50k_mps.png" alt="Alt text"></p>
<p><img src="/images/flume_heka/heka_50k_mem.png" alt="Alt text"></p>
<h1 id="The_Comparison">The Comparison</h1><h2 id="About_Performance">About Performance</h2><p>As the charts said, both Flume and Heka can handle huge amout of log in very high speed. We usually deploy them on servers which act as business usage. That means, it would not take much pressure (if we use them behind Apache Kafka - another usage type is sending date <strong>TO</strong> Kafka, they could work well). Considering the Linux system costs, Heka takes advantages on %MEM while Flume does on %CPU. Heka is written in Golang so that the memory usage is much lower than Flume which is Java made. For %CPU, Flume uses less cpu than Heka. Chars are below:</p>
<p><img src="/images/flume_heka/total_mem.png" alt="Alt text"></p>
<p><img src="/images/flume_heka/total_cpu.png" alt="Alt text"></p>
<h2 id="About_Usability">About Usability</h2><h3 id="Features">Features</h3><p>Flume’s configuration files are written in YAML while Heka’s in TOML. We can find out that writing in TOML is much more simple than YAML as well as we can understand more easily. As for the architectures, Flume is easier. It contains three main components - Source, Channel and Sink. <code>Source</code> defines the date source; <code>Sink</code> defines the destination of the date; <code>Channel</code> is the buffer date pipeline between <code>Source</code> and <code>Sink</code>. In our exmple, log files is the <code>Source</code> and Kafka is the <code>Sink</code>. <code>Source</code> puts date into <code>Channel</code> while <code>Sink</code> takes date from <code>Channel</code>. The architecture is like below:</p>
<p><img src="/images/flume_heka/flume_arch.png" alt="Alt text"></p>
<p>For Heka, its architecture is a little complex. Its <code>Inputs</code>, <code>Outputs</code> are like Flume’s <code>Source</code> and <code>Sink</code>. Heka adds many feature such as <code>Splitter</code>, <code>Decoder</code>, <code>Filter</code> and <code>Encoder</code> in addition. These feature enable Heka to handle date directly in Heka itself, in the same time, make Heka a more powerful tool in comparison of Flume. The architecture is like below: </p>
<p><img src="/images/flume_heka/heka_arch" alt="Alt text"></p>
<h3 id="Monitor">Monitor</h3><p>Both Flume and Heka enables HTTP API to get metrics. </p>
<p>For Flume, we can add JVM parameters <code>-Dflume.monitoring.type=http -Dflume.monitoring.port=34545</code> to enable the HTTP API. And the date is like below (by <code>curl -s localhost:34545/metrics | python -m json.tool</code>):</p>
<pre><code><span class="collection">{
       <span class="string">"CHANNEL.memChannel"</span>: <span class="collection">{
           <span class="string">"ChannelCapacity"</span>: <span class="string">"1000000"</span>,
           <span class="string">"ChannelFillPercentage"</span>: <span class="string">"0.0"</span>,
           <span class="string">"EventPutAttemptCount"</span>: <span class="string">"10"</span>,
           <span class="string">"EventPutSuccessCount"</span>: <span class="string">"10"</span>,
           <span class="string">"EventTakeAttemptCount"</span>: <span class="string">"16"</span>,
           <span class="string">"EventTakeSuccessCount"</span>: <span class="string">"10"</span>,
           <span class="string">"StartTime"</span>: <span class="string">"1458887648261"</span>,
           <span class="string">"StopTime"</span>: <span class="string">"0"</span>,
           <span class="string">"Type"</span>: <span class="string">"CHANNEL"</span>
           }</span>,
           ...
   }</span>
</code></pre><p>For Heka, we need to add this in to its configuration file, <code>ticker_interval</code> defines the interval Heka refresh the data:</p>
<pre><code><span class="title">[DashboardOutput]</span>
<span class="setting">ticker_interval = <span class="value"><span class="number">1</span></span></span>
</code></pre><p>The result is like (by ``):</p>
<pre><code><span class="string">"outputs"</span>: [{
    <span class="string">"Name"</span>: <span class="string">"KafkaOutput"</span>,
    <span class="string">"ProcessMessageCount"</span>: {
        <span class="string">"representation"</span>: <span class="string">"count"</span>,
        <span class="string">"value"</span>: <span class="number">756698</span>
    },
    <span class="string">"ProcessMessageDiscards"</span>: {
        <span class="string">"representation"</span>: <span class="string">"count"</span>,
        <span class="string">"value"</span>: <span class="number">0</span>
    },
    <span class="string">"ProcessMessageFailures"</span>: {
        <span class="string">"representation"</span>: <span class="string">"count"</span>,
        <span class="string">"value"</span>: <span class="number">0</span> }
    },
    ...
}
</code></pre><h3 id="Problems">Problems</h3><ol>
<li><p>Flume cannot read log file continously after restart. Flume uses <code>tail</code> to get log lines from log files so Flume does not know which line it has read or which line it need to start to read after Flume restarts. Heka will keep offset in a meta file and can read the date continously after restarting. In this point, Heka is better.</p>
</li>
<li><p>Flume cannot update log files according to the configurations. For example, we defined we need to get log files named ‘access_*.log’, Flume will not get the files working only when we modify the configuration files. For Heka, Heka will monitor the directory and update the log files in some interval time which is set in configuration files. The parameter is <code>rescan_interval</code>:</p>
</li>
</ol>
<blockquote>
<p>During logfile rotation, or if the logfile is not originally present on the system, this interval is how often the existence of the logfile will be checked for. The default of 5 seconds is usually fine. This interval is in milliseconds.</p>
</blockquote>
<h1 id="Conclusions">Conclusions</h1><p>Both Flume and Heka are good choice for our solutions. Heka is written Golang and we can start/stop it in seconds. For Flume, it always takes minutes to initialize or stop. And Heka can handle the circumstance of continoulsy reading while Flume can not. I think Heka would be a better choice.</p>
<p>But the bad news is that Heka is deprecated by mozilla in May of 2016. We can get the detail inforation <a href="https://mail.mozilla.org/pipermail/heka/2016-May/001059.html" target="_blank" rel="external">here</a>. I thinks there are too many features in Heka and that makes Heka a heavy tool. I like it very much and my plan is to remove the additional components of Heka and make it a simple but powerful tool.</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2016/08/25/Simple-Method-to-Compare-to-JSON-in-Python/" itemprop="url">
                Simple Method to Compare to JSON in Python
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          Posted on
          <time itemprop="dateCreated" datetime="2016-08-25T17:20:58+08:00" content="2016-08-25">
            2016-08-25
          </time>
        </span>

        

        
          
            <span class="post-comments-count">
            &nbsp; | &nbsp;
            <a href="/2016/08/25/Simple-Method-to-Compare-to-JSON-in-Python/#comments" itemprop="discussionUrl">
              <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/08/25/Simple-Method-to-Compare-to-JSON-in-Python/" itemprop="commentsCount"></span>
            </a>
          </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><h1 id="Problem">Problem</h1><p>Recently I met a problem about how to compare to JSON. As we know, JSON is dict-like data structure, the order of its content is not import in the comparison. For example, <code>{&#39;name&#39;: &#39;frank&#39;, &#39;age&#39;: &#39;12&#39;}</code> equals <code>{&#39;age&#39;: &#39;12&#39;, &#39;name&#39;: &#39;frank&#39;}</code>. In the real world, perhaps there are some more complex data structures like list, tuple or nested-dict. </p>
<h1 id="Solutions">Solutions</h1><p>In python(both python2 and python3), we can use <code>pprint</code> to get pretty print for JSON and other data structures. It will sort and format data first. And there is another method in <code>pprint</code> module called <code>pformat</code> which is used to get the output to a string. Let’s see the example.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line">d1 = &#123;<span class="string">'name'</span>: <span class="string">'frank'</span>, <span class="string">'age'</span>: <span class="string">'12'</span>&#125;</span><br><span class="line">pformat_d1 = pprint.pformat(d1) <span class="comment"># pformat_d1: &#123;'age': '12', 'name': 'frank'&#125;</span></span><br><span class="line">d2 = &#123;<span class="string">'age'</span>: <span class="string">'12'</span>, <span class="string">'name'</span>: <span class="string">'frank'</span>&#125;</span><br><span class="line">pformat_d2 = pprint.pformat(d2) <span class="comment"># pformat_d2: &#123;'age': '12', 'name': 'frank'&#125;</span></span><br></pre></td></tr></table></figure></span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2016/08/05/Run-pyspark-in-Python3/" itemprop="url">
                Run pyspark in Python3
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          Posted on
          <time itemprop="dateCreated" datetime="2016-08-05T17:47:53+08:00" content="2016-08-05">
            2016-08-05
          </time>
        </span>

        

        
          
            <span class="post-comments-count">
            &nbsp; | &nbsp;
            <a href="/2016/08/05/Run-pyspark-in-Python3/#comments" itemprop="discussionUrl">
              <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/08/05/Run-pyspark-in-Python3/" itemprop="commentsCount"></span>
            </a>
          </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><h1 id="Backgroud">Backgroud</h1><p>We were using spark in Scala environment for a long time and it did its job well. Now we need to query spark in python3 scripts and this post is a simple how-to guide for pyspark.</p>
<h1 id="Prerequisites">Prerequisites</h1><ol>
<li>jdk</li>
<li>spark</li>
<li>python3</li>
<li>set <code>JAVA_HOME</code> and <code>SPARK_HOME</code> in env</li>
</ol>
<p><code>pyspark</code> is in your <code>SPARK_HOME/python</code>, you need to put it into you python path. You can <code>cp</code> or <code>ln</code> the directory to you python3 path, another method is use <code>sys.path.append</code> in your scripts.</p>
<h1 id="Example">Example</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext, SparkConf</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> HiveContext</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    conf = SparkConf()</span><br><span class="line">    conf.set(<span class="string">'spark.executor.memory'</span>, <span class="string">'16g'</span>)</span><br><span class="line">    sc = SparkContext(<span class="string">'spark://10.3.99.42:7077'</span>, appName=<span class="string">'test'</span>, conf=conf)</span><br><span class="line">    sc.setLogLevel(<span class="string">'ERROR'</span>)</span><br><span class="line">    hiveContext = HiveContext(sc)</span><br><span class="line">    hiveContext.setConf(<span class="string">'hive.metastore.uris'</span>, <span class="string">'thrift://127.0.0.1:9083'</span>)</span><br><span class="line">    hiveContext.setConf(<span class="string">'io.compression.codecs'</span>, <span class="string">'org.apache.hadoop.io.compress.SnappyCodec'</span>)</span><br><span class="line">    hiveContext.sql(<span class="string">'use default'</span>)</span><br><span class="line">    hiveContext.sql(<span class="string">"select * from table"</span>).show()</span><br></pre></td></tr></table></figure></span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2016/07/08/Enable-lzo-in-Spark-and-IntelliJ-IDEA/" itemprop="url">
                Enable lzo in Spark and IntelliJ IDEA
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          Posted on
          <time itemprop="dateCreated" datetime="2016-07-08T09:32:13+08:00" content="2016-07-08">
            2016-07-08
          </time>
        </span>

        

        
          
            <span class="post-comments-count">
            &nbsp; | &nbsp;
            <a href="/2016/07/08/Enable-lzo-in-Spark-and-IntelliJ-IDEA/#comments" itemprop="discussionUrl">
              <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/07/08/Enable-lzo-in-Spark-and-IntelliJ-IDEA/" itemprop="commentsCount"></span>
            </a>
          </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><h1 id="Intro">Intro</h1><p>LZO is a compression codec for Hadoop-environment component like hadoop, hbase, spark and so on. The problem I met is that I want to read and calculate data from Hive table in lzo by SparkSQL. In this post, I will show you how to enable lzo in a Spark box without extra hadoop lib and run SparkSQL in Intellij IDEA in Mac.</p>
<h1 id="Box">Box</h1><ul>
<li>spark-1.6.2-bin-hadoop2.6</li>
<li>jdk-1.7</li>
<li>hadoop-lzo-0.4.20</li>
<li>maven3</li>
</ul>
<p>Spark node run on CentOS 7, and Intellij IDEA is on OS X EI Capitan.</p>
<h1 id="Enable_lzo_in_spark_node">Enable lzo in spark node</h1><p>You can run spark in standalone without any other component, so it is easy to test wheather we have enable lzo. </p>
<h4 id="Install_linux_lzo_dependencies_by_yum">Install linux lzo dependencies by yum</h4><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum <span class="keyword">install</span> -y lzo-devel lzop</span><br></pre></td></tr></table></figure>
<h4 id="clone_hadoop-lzo_repo_from_github">clone hadoop-lzo repo from github</h4><p>Clone it at <a href="https://github.com/twitter/hadoop-lzo" target="_blank" rel="external">https://github.com/twitter/hadoop-lzo</a>. Then use maven.</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone <span class="string">https:</span><span class="comment">//github.com/twitter/hadoop-lzo</span></span><br><span class="line">cd hadoop-lzo</span><br><span class="line">mvn <span class="keyword">package</span></span><br></pre></td></tr></table></figure>
<p>After package it, you will get a jar named <code>hadoop-lzo-0.4.20-SNAPSHOT.jar</code> in <code>target</code> directory.</p>
<h4 id="Add_jar_to_spark_env_by_set_env_in_${SPARK_HOME}/conf/spark-conf-sh-">Add jar to spark env by set env in <code>${SPARK_HOME}/conf/spark-conf.sh</code>.</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> SPARK_CLASSPATH=$&#123;HADOOP-LZO_HOME&#125;/target/hadoop-lzo-<span class="number">0.4</span><span class="number">.20</span>-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>
<p><code>${SPARK_HOME}</code> and <code>${HADOOP-LZO_HOME}</code> is the directory you put spark and hadoop-lzo repo.</p>
<h4 id="Run_spark_in_standalone_mode-">Run spark in standalone mode.</h4><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cd</span> <span class="label">$&#123;SPARK_HOME&#125;</span></span><br><span class="line">./sbin/start-master.<span class="keyword">sh</span></span><br><span class="line">./sbin/start-slave.<span class="keyword">sh</span> spark:<span class="comment">//$&#123;SPARK_IP&#125;:$&#123;SPARK_PORT&#125;</span></span><br></pre></td></tr></table></figure>
<h4 id="Test_if_lzo_is_availabe_in_spark_by_spark-shell-">Test if lzo is availabe in spark by <code>spark-shell</code>.</h4><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">cd $&#123;SPARK_HOME&#125;</span><br><span class="line">./bin/spark-shell</span><br><span class="line">scala&gt; sqlContext.setConf(<span class="string">"hive.metastore.uris"</span>, <span class="string">"thrift://cloudera-server:9083"</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; sqlContext.setConf(<span class="string">"io.compression.codecs"</span>, <span class="string">"com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec"</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; sqlContext.sql(<span class="string">"use default"</span>)</span><br><span class="line">res2: org.apache.spark.sql.DataFrame = [result: string]</span><br><span class="line"></span><br><span class="line">scala&gt; sqlContext.sql(<span class="string">"select cdn_ip, timestamp from total_cdn_log where date='2016-07-05' and hour='01' limit 10"</span>).show()</span><br><span class="line">+-----------+----------+</span><br><span class="line">|<span class="string">     cdn_ip</span>|<span class="string"> timestamp</span>|</span><br><span class="line">+-----------+----------+</span><br><span class="line">|<span class="string">cdn_ip_none</span>|<span class="string">1467651600</span>|</span><br><span class="line">|<span class="string">cdn_ip_none</span>|<span class="string">1467651600</span>|</span><br><span class="line">|<span class="string">cdn_ip_none</span>|<span class="string">1467651600</span>|</span><br><span class="line">|<span class="string">cdn_ip_none</span>|<span class="string">1467651600</span>|</span><br><span class="line">|<span class="string">cdn_ip_none</span>|<span class="string">1467651600</span>|</span><br><span class="line">|<span class="string">cdn_ip_none</span>|<span class="string">1467651600</span>|</span><br><span class="line">|<span class="string">cdn_ip_none</span>|<span class="string">1467651600</span>|</span><br><span class="line">|<span class="string">cdn_ip_none</span>|<span class="string">1467651600</span>|</span><br><span class="line">|<span class="string">cdn_ip_none</span>|<span class="string">1467651600</span>|</span><br><span class="line">|<span class="string">cdn_ip_none</span>|<span class="string">1467651600</span>|</span><br><span class="line">+-----------+----------+</span><br></pre></td></tr></table></figure>
<p>We must set <code>io.compression.codecs</code> to <code>com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec</code> because spark use snappy codec in default.</p>
<h1 id="Enable_lzo_in_IntelliJ_IDEA">Enable lzo in IntelliJ IDEA</h1><p>I think you have make your SparkSQL job running - that is to say, scala box is okay in your IntelliJ IDEA. Mac OS is a little different with RedHat because it is based on FreeBSD and NetBSD’s implementions.</p>
<h4 id="Install_lzo_dependencies_by_brew">Install lzo dependencies by <code>brew</code></h4><p><code>brew</code> is an excellent package management tool in Mac which its full name is <code>Homebrew</code>. If you have not installed <code>brew</code>, you can go to its website <a href="http://brew.sh/" target="_blank" rel="external">http://brew.sh/</a>. Its install is easy with only one line command.</p>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="regexp">/usr/</span>bin<span class="regexp">/ruby -e "$(curl -fsSL https:/</span><span class="regexp">/raw.githubusercontent.com/</span>Homebrew<span class="regexp">/install/m</span>aster<span class="regexp">/install)"</span></span><br></pre></td></tr></table></figure>
<p>Okay, let’s install <code>lzo</code> dependencies.</p>
<figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">brew </span>install lzo lzop</span><br></pre></td></tr></table></figure>
<h4 id="Package_hadoop-lzo">Package <code>hadoop-lzo</code></h4><p><strong>REMARK:</strong> Please <strong>DO NOT</strong> copy the <code>hadoop-lzo</code> from other system - such as CentOS that we run spark on. Because the maven procedure in <code>hadoop-lzo</code> contains some <code>gcc</code> process which is strongly connected with the system.</p>
<p>To build <code>hadoop-lzo</code>, we need to specify the location we install <code>lzo</code>. </p>
<figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$ </span>brew list lzo</span><br><span class="line">/usr/local/<span class="constant">Cellar</span>/lzo/<span class="number">2.09</span>/<span class="keyword">include</span>/lzo/ (<span class="number">13</span> files)</span><br><span class="line">/usr/local/<span class="constant">Cellar</span>/lzo/<span class="number">2.09</span>/<span class="class"><span class="keyword">lib</span>/<span class="title">liblzo2</span>.2.<span class="title">dylib</span></span></span><br><span class="line">/usr/local/<span class="constant">Cellar</span>/lzo/<span class="number">2.09</span>/<span class="class"><span class="keyword">lib</span>/ (2 <span class="title">other</span> <span class="title">files</span>)</span></span><br><span class="line">/usr/local/<span class="constant">Cellar</span>/lzo/<span class="number">2.09</span>/share/doc/ (<span class="number">7</span> files)</span><br></pre></td></tr></table></figure>
<p>Then we can get <code>hadoop-lzo</code> and package jar.</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git clone <span class="string">https:</span><span class="comment">//github.com/twitter/hadoop-lzo</span></span><br><span class="line">$ cd hadoop-lzo</span><br><span class="line">$ C_INCLUDE_PATH=<span class="regexp">/usr/</span>local<span class="regexp">/Cellar/</span>lzo<span class="regexp">/2.09/</span>include<span class="regexp">/ LIBRARY_PATH=/</span>usr<span class="regexp">/local/</span>Cellar<span class="regexp">/lzo/</span><span class="number">2.09</span><span class="regexp">/lib/</span>   mvn clean <span class="keyword">package</span></span><br></pre></td></tr></table></figure>
<p><strong>REMARK:</strong> The guide <a href="https://gist.github.com/zedar/c43cbc7ff7f98abee885" target="_blank" rel="external">https://gist.github.com/zedar/c43cbc7ff7f98abee885</a> - Add LZO compresssion codecs to the Apache Hadoop and Spark is little wrong for set <code>C_INCLUDE_PATH</code>. In the guide, he said<br><code>C_INCLUDE_PATH=/usr/local/Cellar/lzo/2.06/include/lzo/</code>, it should be <code>C_INCLUDE_PATH=/usr/local/Cellar/lzo/2.09/include/</code>. We do not need add lzo suffix.</p>
<h4 id="Config_the_IntelliJ_IDEA_box">Config the IntelliJ IDEA box</h4><p>The first step is add <code>hadoop-lzo-0.4.20-SNAPSHOT.jar</code> to your scala project.</p>
<p><img src="/images/idea_lzo_add_jar.png" alt="Alt text"></p>
<p>The next step is add <code>java.library.path</code> to your jvm options in your menu <code>Run-Edit configurations...</code>. The option you need to add is like <code>-Djava.library.path=/Users/yaorenjie/Documents/git/hadoop-lzo/target</code></p>
<p><img src="/images/idea_lzo_add_jvm.png" alt="Alt text"></p>
<p><strong>REMARK:</strong> You must specify the build directory you run maven. If you want to use other directory, you <strong>MUST</strong> move all files in <code>target</code>. The <code>hadoop-lzo</code> need native <code>gpl</code> library in <code>target</code> directory.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ll native/Mac_OS_X-x86_64-<span class="number">64</span>/lib</span><br><span class="line">total <span class="number">208</span></span><br><span class="line">-rwxr-xr-x  <span class="number">1</span> yaorenjie  staff  <span class="number">21780</span> Jul  <span class="number">7</span> <span class="number">17</span>:<span class="number">36</span> libgplcompression<span class="number">.0</span>.dylib</span><br><span class="line">-rw-r--r--  <span class="number">1</span> yaorenjie  staff   <span class="number">1164</span> Jul  <span class="number">7</span> <span class="number">17</span>:<span class="number">36</span> libgplcompression.la</span><br><span class="line">lrwxr-xr-x  <span class="number">1</span> yaorenjie  staff     <span class="number">25</span> Jul  <span class="number">7</span> <span class="number">17</span>:<span class="number">36</span> libgplcompression.dylib -&gt; libgplcompression<span class="number">.0</span>.dylib</span><br><span class="line">-rw-r--r--  <span class="number">1</span> yaorenjie  staff  <span class="number">69744</span> Jul  <span class="number">7</span> <span class="number">17</span>:<span class="number">36</span> libgplcompression.a</span><br></pre></td></tr></table></figure>
<p>If you want to dig it out, you can get this process in <code>GPLNativeCodeLoader</code></p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2016/07/04/Connect-MySQL-with-ssh-tunnel-in-Python/" itemprop="url">
                Connect MySQL with ssh tunnel in Python
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          Posted on
          <time itemprop="dateCreated" datetime="2016-07-04T14:45:41+08:00" content="2016-07-04">
            2016-07-04
          </time>
        </span>

        

        
          
            <span class="post-comments-count">
            &nbsp; | &nbsp;
            <a href="/2016/07/04/Connect-MySQL-with-ssh-tunnel-in-Python/#comments" itemprop="discussionUrl">
              <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/07/04/Connect-MySQL-with-ssh-tunnel-in-Python/" itemprop="commentsCount"></span>
            </a>
          </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>Sometimes you can only connect to MySQL via a certain server for security reasons. But apparently, coding in IDE(e.g PyCharm) is easier. For this circumstance, we can use <a href="https://pypi.python.org/pypi/sshtunnel" target="_blank" rel="external">sshtunnel</a>.</p>
<p>So we have a MySQL server on <code>127.0.0.3:3306</code>, its mysql login name and password is <code>MYSQL_USER</code> and <code>MYSQL_PASSWORD</code>. And we can only connect to this mysql via server <code>127.0.0.2:22</code>, and its login name and password is <code>root</code> and <code>SERVER_PASSWORD</code>. Let’s figure out how <code>sshtunnel</code> is working.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> SSHTunnelForwarder((<span class="string">'127.0.0.2'</span>, <span class="number">22</span>), ssh_password=<span class="string">'SERVER_PASSWORD'</span>, ssh_username=<span class="string">'root'</span>, remote_bind_address=(<span class="string">'127.0.0.3'</span>, <span class="number">3306</span>)) <span class="keyword">as</span> server:</span><br><span class="line">       conn = MySQLdb.connect(host=<span class="string">'127.0.0.1'</span>, port=server.local_bind_port, user=<span class="string">'MYSQL_USER'</span>, passwd=<span class="string">'MYSQL_PASSWORD'</span>)</span><br><span class="line">       cursor = conn.cursor()</span><br></pre></td></tr></table></figure>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2016/06/20/Using-pip-and-easy-install-with-Chinese-repo/" itemprop="url">
                Using pip and easy_install with Chinese repo
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          Posted on
          <time itemprop="dateCreated" datetime="2016-06-20T15:47:16+08:00" content="2016-06-20">
            2016-06-20
          </time>
        </span>

        

        
          
            <span class="post-comments-count">
            &nbsp; | &nbsp;
            <a href="/2016/06/20/Using-pip-and-easy-install-with-Chinese-repo/#comments" itemprop="discussionUrl">
              <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/06/20/Using-pip-and-easy-install-with-Chinese-repo/" itemprop="commentsCount"></span>
            </a>
          </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>For some reasons, <code>pypi.python.org</code> is not available or has a slow download rate. We can simply using <a href="http://pypi.douban.com/simple" target="_blank" rel="external">douban pypi</a> or <a href="http://pypi.v2ex.com/simple" target="_blank" rel="external">v2ex pypi</a> by two ways.</p>
<h2 id="edit_env">edit env</h2><p>Edit env will enable <code>pip</code> using own pypi in default. In Linux and Mac, the file is in <code>%HOME/.pip/pip.conf</code>. And the content is:</p>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[global]</span><br><span class="line"><span class="keyword">find</span>-links=http:<span class="comment">//pypi.douban.com/simple</span></span><br><span class="line">[install]</span><br><span class="line"><span class="keyword">find</span>-links=</span><br><span class="line">    http:<span class="comment">//pypi.douban.com/simple</span></span><br><span class="line">    http:<span class="comment">//pypi.v2ex.com/simple</span></span><br></pre></td></tr></table></figure></span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">&raquo;</a>
  </nav>

 </div>

        

        
      </div>

      
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      <section class="site-overview">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" src="/images/avatar-hippo.jpg" alt="Renjie Yao" itemprop="image"/>
          <p class="site-author-name" itemprop="name">Renjie Yao</p>
        </div>
        <p class="site-description motion-element" itemprop="description"></p>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">21</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          <div class="site-state-item site-state-categories">
            
              <span class="site-state-item-count">0</span>
              <span class="site-state-item-name">categories</span>
              
          </div>

          <div class="site-state-item site-state-tags">
            <a href="/tags">
              <span class="site-state-item-count">39</span>
              <span class="site-state-item-name">tags</span>
              </a>
          </div>

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="menu-item-icon icon-next-feed"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/baniuyao" target="_blank">github</a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/frankymryao" target="_blank">weibo</a>
              </span>
            
          
        </div>

        
        

        <div class="links-of-author motion-element">
          
        </div>

      </section>

      

    </div>
  </aside>


    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner"> <div class="copyright" >
  
  &copy; &nbsp; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="icon-next-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Renjie Yao</span>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="http://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT
  </a>
</div>


 </div>
    </footer>

    <div class="back-to-top"></div>
  </div>

  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  
  
    
    

  

    <script type="text/javascript">
      var disqus_shortname = 'renjieyaoblog';
      var disqus_identifier = 'index.html';
      var disqus_title = '';
      var disqus_url = '';

      function run_disqus_script(disqus_script){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      }

      run_disqus_script('count.js');
      
    </script>
  


  
  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/fancy-box.js?v=0.4.5.1"></script>


  <script type="text/javascript" src="/js/helpers.js?v=0.4.5.1"></script>
  

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/js/motion_global.js?v=0.4.5.1" id="motion.global"></script>




  <script type="text/javascript" src="/js/nav-toggle.js?v=0.4.5.1"></script>
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  

  <script type="text/javascript">
    $(document).ready(function () {
      if (CONFIG.sidebar === 'always') {
        displaySidebar();
      }
      if (isMobile()) {
        FastClick.attach(document.body);
      }
    });
  </script>

  

  
  

  
  <script type="text/javascript" src="/js/lazyload.js"></script>
  <script type="text/javascript">
    $(function () {
      $("#posts").find('img').lazyload({
        placeholder: "/images/loading.gif",
        effect: "fadeIn"
      });
    });
  </script>
</body>
</html>
